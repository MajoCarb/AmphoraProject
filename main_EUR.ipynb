{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## AMPHORA CHALLENGE\n",
    "### By María José Carbajal Alonso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>superpopulation_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NA19625</th>\n",
       "      <td>AFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA19835</th>\n",
       "      <td>AFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA19900</th>\n",
       "      <td>AFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA19917</th>\n",
       "      <td>AFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA19703</th>\n",
       "      <td>AFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA19201</th>\n",
       "      <td>AFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA19206</th>\n",
       "      <td>AFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA19213</th>\n",
       "      <td>AFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA19225</th>\n",
       "      <td>AFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA19143</th>\n",
       "      <td>AFR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2504 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            superpopulation_code\n",
       "sample_name                     \n",
       "NA19625                      AFR\n",
       "NA19835                      AFR\n",
       "NA19900                      AFR\n",
       "NA19917                      AFR\n",
       "NA19703                      AFR\n",
       "...                          ...\n",
       "NA19201                      AFR\n",
       "NA19206                      AFR\n",
       "NA19213                      AFR\n",
       "NA19225                      AFR\n",
       "NA19143                      AFR\n",
       "\n",
       "[2504 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ancestry file\n",
    "#ancestry_file = pd.read_csv('drive/MyDrive/Amphora/ancestry-1000genome.tsv', sep='\\t')\n",
    "ancestry_file = pd.read_csv('ancestry-1000genome.tsv', sep='\\t')\n",
    "\n",
    "#Superpopulation code dataframe\n",
    "spp_code = pd.DataFrame()\n",
    "spp_code['sample_name'] = ancestry_file['Sample name']\n",
    "\n",
    "#getting only the patients \n",
    "patients = spp_code['sample_name']\n",
    "\n",
    "spp_code['superpopulation_code'] = ancestry_file['Superpopulation code']\n",
    "spp_code.set_index('sample_name', inplace=True)\n",
    "\n",
    "#getting the 5 categories we will use (ancestry types)\n",
    "ancestry_types = list(spp_code['superpopulation_code'].unique())\n",
    "\n",
    "spp_code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NA20876' 'HG01148' 'HG01366' 'HG01992' 'HG01851']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2504"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reduction of number of patients using a sample of 100%, random state makes that the sample be the same \n",
    "\n",
    "patients_=patients.sample(frac=1, random_state=1)\n",
    "list(patients_.head(1).values)[0]\n",
    "print(str(np.array(patients_[:5])))\n",
    "len(patients_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame()\n",
    "lenn= 10028 #total len = 10028 of chr:location list\n",
    "\n",
    "for patient in patients_:   \n",
    "\n",
    "    #Getting the patient's information fron its CSV file\n",
    "    #patient_x = pd.read_csv('drive/MyDrive/Amphora/Challenge_Samples/'+patient+'.csv')\n",
    "    patient_x = pd.read_csv('Challenge_Samples/'+patient+'.csv')\n",
    "    patient_x.rename(columns={patient:'Presence'},inplace=True)\n",
    "    \n",
    "    #Creating Presence list    \n",
    "    presence_list = list(patient_x['Presence'])\n",
    "    presence_list=presence_list[:lenn]\n",
    "\n",
    "    #Creating a string value that contains all the information of Chr:Location, ALT and Presence\n",
    "    sequence = (\"\".join(map(str, presence_list)))\n",
    "\n",
    "    #Getting the Superpopulation Code \n",
    "    code = list(spp_code[spp_code.index==patient]['superpopulation_code'] )\n",
    "    code = code[0]\n",
    "\n",
    "    #Getting the values for the three nationalities we're going to predict\n",
    "    \n",
    "    afr_res = 1  if code == 'AFR' else 0\n",
    "    eur_res = 1  if code == 'EUR' else 0\n",
    "    asian_res = 1  if code == 'SAS' or code == 'EAS' else 0\n",
    "\n",
    "    #creating the data and the columns of the dataframe\n",
    "    data = [patient, code, sequence, afr_res, eur_res, asian_res]\n",
    "    col = ['Patient', 'SPP_code', 'Sequence', 'AFR', 'EUR','ASIAN']\n",
    "\n",
    "    \n",
    "    sample = {'Patient':patient, 'SPP_code':code, 'Sequence':sequence, 'AFR':afr_res, 'EUR': eur_res,'ASIAN':asian_res}\n",
    "    data\n",
    "\n",
    "    df = pd.DataFrame(columns=col)\n",
    "    df=df.append(sample, ignore_index=True)\n",
    "    df.set_index('Patient')\n",
    "\n",
    "    main_df = pd.concat([main_df,df], axis=0)\n",
    "\n",
    "    \n",
    "\n",
    "#patients_main_df=list(set(main_df.index.get_level_values('Patient')))\n",
    "#spp_code_main_df=list(set(main_df.index.get_level_values('Superpopulation Code')))\n",
    "main_df=main_df.set_index('Patient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>SPP_code</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>AFR</th>\n",
       "      <th>EUR</th>\n",
       "      <th>ASIAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA20876</td>\n",
       "      <td>SAS</td>\n",
       "      <td>0000101011011010111011100010000010100011101000...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HG01148</td>\n",
       "      <td>AMR</td>\n",
       "      <td>0110100011011010111010000110000010100010110000...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HG01366</td>\n",
       "      <td>AMR</td>\n",
       "      <td>0011100111011010111011000010000011100000110000...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HG01992</td>\n",
       "      <td>AMR</td>\n",
       "      <td>0110100011111010111011000010001011101001101010...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HG01851</td>\n",
       "      <td>EAS</td>\n",
       "      <td>0001100000011000111011000010000011000101101000...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>NA20901</td>\n",
       "      <td>SAS</td>\n",
       "      <td>0101110011011010110001100110000011110111111000...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>HG02861</td>\n",
       "      <td>AFR</td>\n",
       "      <td>0011100001111110101000100110000011001011110000...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>NA18637</td>\n",
       "      <td>EAS</td>\n",
       "      <td>0100100000011000111011000010000001000101101000...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>HG03809</td>\n",
       "      <td>SAS</td>\n",
       "      <td>0101110011001010111011100010000011110011111000...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>NA18557</td>\n",
       "      <td>EAS</td>\n",
       "      <td>0000100010101000011011100010000001000011100010...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2504 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Patient SPP_code                                           Sequence  \\\n",
       "0     NA20876      SAS  0000101011011010111011100010000010100011101000...   \n",
       "1     HG01148      AMR  0110100011011010111010000110000010100010110000...   \n",
       "2     HG01366      AMR  0011100111011010111011000010000011100000110000...   \n",
       "3     HG01992      AMR  0110100011111010111011000010001011101001101010...   \n",
       "4     HG01851      EAS  0001100000011000111011000010000011000101101000...   \n",
       "...       ...      ...                                                ...   \n",
       "2499  NA20901      SAS  0101110011011010110001100110000011110111111000...   \n",
       "2500  HG02861      AFR  0011100001111110101000100110000011001011110000...   \n",
       "2501  NA18637      EAS  0100100000011000111011000010000001000101101000...   \n",
       "2502  HG03809      SAS  0101110011001010111011100010000011110011111000...   \n",
       "2503  NA18557      EAS  0000100010101000011011100010000001000011100010...   \n",
       "\n",
       "      AFR  EUR  ASIAN  \n",
       "0       0    0      1  \n",
       "1       0    0      0  \n",
       "2       0    0      0  \n",
       "3       0    0      0  \n",
       "4       0    0      1  \n",
       "...   ...  ...    ...  \n",
       "2499    0    0      1  \n",
       "2500    1    0      0  \n",
       "2501    0    0      1  \n",
       "2502    0    0      1  \n",
       "2503    0    0      1  \n",
       "\n",
       "[2504 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993 661 503\n"
     ]
    }
   ],
   "source": [
    "print(main_df['ASIAN'].sum(),\n",
    "main_df['AFR'].sum(),\n",
    "main_df['EUR'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the dataframe into a CSV file at Google Drive or locally\n",
    "#main_df.to_csv('drive/MyDrive/Amphora/main_df_100%_seq.csv', index=True)\n",
    "#main_df.to_csv('main_df_100%_seq.csv', index=True)\n",
    "#df_from_file = pd.read_csv('drive/MyDrive/Amphora/main_df_100%_seq.csv')\n",
    "df_from_file = pd.read_csv('main_df_100%_seq.csv')\n",
    "\n",
    "main_df = df_from_file\n",
    "#main_df.set_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>SPP_code</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>AFR</th>\n",
       "      <th>EUR</th>\n",
       "      <th>ASIAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA20876</td>\n",
       "      <td>SAS</td>\n",
       "      <td>0000101011011010111011100010000010100011101000...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HG01148</td>\n",
       "      <td>AMR</td>\n",
       "      <td>0110100011011010111010000110000010100010110000...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HG01366</td>\n",
       "      <td>AMR</td>\n",
       "      <td>0011100111011010111011000010000011100000110000...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HG01992</td>\n",
       "      <td>AMR</td>\n",
       "      <td>0110100011111010111011000010001011101001101010...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HG01851</td>\n",
       "      <td>EAS</td>\n",
       "      <td>0001100000011000111011000010000011000101101000...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>NA20901</td>\n",
       "      <td>SAS</td>\n",
       "      <td>0101110011011010110001100110000011110111111000...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>HG02861</td>\n",
       "      <td>AFR</td>\n",
       "      <td>0011100001111110101000100110000011001011110000...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>NA18637</td>\n",
       "      <td>EAS</td>\n",
       "      <td>0100100000011000111011000010000001000101101000...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>HG03809</td>\n",
       "      <td>SAS</td>\n",
       "      <td>0101110011001010111011100010000011110011111000...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>NA18557</td>\n",
       "      <td>EAS</td>\n",
       "      <td>0000100010101000011011100010000001000011100010...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2504 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Patient SPP_code                                           Sequence  \\\n",
       "0     NA20876      SAS  0000101011011010111011100010000010100011101000...   \n",
       "1     HG01148      AMR  0110100011011010111010000110000010100010110000...   \n",
       "2     HG01366      AMR  0011100111011010111011000010000011100000110000...   \n",
       "3     HG01992      AMR  0110100011111010111011000010001011101001101010...   \n",
       "4     HG01851      EAS  0001100000011000111011000010000011000101101000...   \n",
       "...       ...      ...                                                ...   \n",
       "2499  NA20901      SAS  0101110011011010110001100110000011110111111000...   \n",
       "2500  HG02861      AFR  0011100001111110101000100110000011001011110000...   \n",
       "2501  NA18637      EAS  0100100000011000111011000010000001000101101000...   \n",
       "2502  HG03809      SAS  0101110011001010111011100010000011110011111000...   \n",
       "2503  NA18557      EAS  0000100010101000011011100010000001000011100010...   \n",
       "\n",
       "      AFR  EUR  ASIAN  \n",
       "0       0    0      1  \n",
       "1       0    0      0  \n",
       "2       0    0      0  \n",
       "3       0    0      0  \n",
       "4       0    0      1  \n",
       "...   ...  ...    ...  \n",
       "2499    0    0      1  \n",
       "2500    1    0      0  \n",
       "2501    0    0      1  \n",
       "2502    0    0      1  \n",
       "2503    0    0      1  \n",
       "\n",
       "[2504 rows x 6 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Here starts the section of training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def createLabelEncoder(df):\n",
    "    #creating labelEncoder\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    # Converting string labels into numbers.\n",
    "    seq_encoded=le.fit_transform(df['Sequence'])\n",
    "\n",
    "    #print(set(list(seq_encoded)))\n",
    "    type(seq_encoded)\n",
    "    list(le.classes_)\n",
    "\n",
    "    return seq_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's CREATE A FUNCTION to preprocess the data of sequence in order to have an int value to fit the model\n",
    "\n",
    "# Import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def createLabelEncoder(df):\n",
    "    #creating labelEncoder\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    # Converting string labels into numbers.\n",
    "    seq_encoded=le.fit_transform(df['Sequence'])\n",
    "\n",
    "    #print(set(list(seq_encoded)))\n",
    "    type(seq_encoded)\n",
    "    list(le.classes_)\n",
    "\n",
    "    return seq_encoded\n",
    "\n",
    "#function for any model\n",
    "\n",
    "def modelData(df, modelClass):\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    seq_encoded = createLabelEncoder(df)\n",
    "\n",
    "    # Declare X and y variables\n",
    "    x= seq_encoded\n",
    "    x = x.reshape(-1, 1)\n",
    "    y = df[[df.columns[2]]].values\n",
    "    \n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, train_size=0.8,random_state=1)\n",
    "\n",
    "    if modelClass == 'knn':\n",
    "        model = KNeighborsClassifier()\n",
    "        print('MODEL CHOSEN: KNN\\n')\n",
    "    elif modelClass == 'gnb':\n",
    "        model = GaussianNB()\n",
    "        print('MODEL CHOSEN: Naive Bayes\\n')\n",
    "    elif modelClass == 'rfc':\n",
    "        model = RandomForestClassifier()\n",
    "        print('MODEL CHOSEN: Random Forest\\n')\n",
    "    elif modelClass == 'logreg':\n",
    "        model = RandomForestClassifier()\n",
    "        print('MODEL CHOSEN: Logistic Regression\\n')\n",
    "\n",
    "            \n",
    "    cv_scores = cross_val_score(model, X_train,np.ravel(y_train), cv=10,scoring='accuracy')\n",
    "\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred=model.predict(X_test)\n",
    "\n",
    "\n",
    "    # print the first 10 predicted probabilities of class membership\n",
    "    y_pred_prob=model.predict_proba(X_test)\n",
    "\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Model Precision: what percentage of positive tuples are labeled as such?\n",
    "    print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "    # Model Recall: what percentage of positive tuples are labelled as such?\n",
    "    print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "    # Model Accuracy: how often is the classifier correct?\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print('Acuracy cv_scores mean:{}'.format(np.mean(cv_scores)))\n",
    "\n",
    "    # IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "    print(\"AUC: \",metrics.roc_auc_score(y_test, y_pred_prob[:, 1]))\n",
    "\n",
    "    print(\"cross-validated AUC: \",cross_val_score(rfc, X_train,np.ravel(y_train), cv=10,scoring='roc_auc').mean(),'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **European ancestry KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL CHOSEN: KNN\n",
      "\n",
      "[[350  43]\n",
      " [ 68  40]]\n",
      "Precision: 0.4819277108433735\n",
      "Recall: 0.37037037037037035\n",
      "Accuracy: 0.7784431137724551\n",
      "Acuracy cv_scores mean:0.78531592039801\n",
      "AUC:  0.7651847139760626\n",
      "cross-validated AUC:  0.7596350720158466 \n",
      "\n",
      "MODEL CHOSEN: Logistic Regression\n",
      "\n",
      "[[332  61]\n",
      " [ 65  43]]\n",
      "Precision: 0.41346153846153844\n",
      "Recall: 0.39814814814814814\n",
      "Accuracy: 0.7485029940119761\n",
      "Acuracy cv_scores mean:0.772318407960199\n",
      "AUC:  0.7602252379606069\n",
      "cross-validated AUC:  0.7585363600394172 \n",
      "\n",
      "MODEL CHOSEN: Naive Bayes\n",
      "\n",
      "[[393   0]\n",
      " [108   0]]\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "Accuracy: 0.7844311377245509\n",
      "Acuracy cv_scores mean:0.8027985074626866\n",
      "AUC:  0.6635331260013193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Majo Carbajal\\anaconda3\\envs\\amphora\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validated AUC:  0.7579993418040293 \n",
      "\n",
      "MODEL CHOSEN: Random Forest\n",
      "\n",
      "[[332  61]\n",
      " [ 66  42]]\n",
      "Precision: 0.4077669902912621\n",
      "Recall: 0.3888888888888889\n",
      "Accuracy: 0.7465069860279441\n",
      "Acuracy cv_scores mean:0.772318407960199\n",
      "AUC:  0.755089058524173\n",
      "cross-validated AUC:  0.7623791942885012 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop the ancestries we are not going to predict\n",
    "df_eur = main_df.drop(['ASIAN', 'AFR'], axis=1)\n",
    "df_eur.set_index(['Patient'],inplace=True)\n",
    "patients_eur_df=list(set(df_eur.index.get_level_values('Patient')))\n",
    "#len(patients_eur_df)\n",
    "\n",
    "modelData(df_eur, 'knn')\n",
    "modelData(df_eur, 'logreg')\n",
    "modelData(df_eur, 'gnb')\n",
    "modelData(df_eur, 'rfc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **African ancestry**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL CHOSEN: Logistic Regression\n",
      "\n",
      "[[340  25]\n",
      " [ 33 103]]\n",
      "Precision: 0.8046875\n",
      "Recall: 0.7573529411764706\n",
      "Accuracy: 0.8842315369261478\n",
      "Acuracy cv_scores mean:0.8861865671641791\n",
      "AUC:  0.9121877518130539\n",
      "cross-validated AUC:  0.9381258545763262 \n",
      "\n",
      "MODEL CHOSEN: KNN\n",
      "\n",
      "[[348  17]\n",
      " [ 28 108]]\n",
      "Precision: 0.864\n",
      "Recall: 0.7941176470588235\n",
      "Accuracy: 0.9101796407185628\n",
      "Acuracy cv_scores mean:0.8931815920398011\n",
      "AUC:  0.9140410958904108\n",
      "cross-validated AUC:  0.9367053090604303 \n",
      "\n",
      "MODEL CHOSEN: Naive Bayes\n",
      "\n",
      "[[365   0]\n",
      " [136   0]]\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "Accuracy: 0.7285429141716567\n",
      "Acuracy cv_scores mean:0.7378955223880597\n",
      "AUC:  0.8936140209508461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Majo Carbajal\\anaconda3\\envs\\amphora\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validated AUC:  0.9402232699065584 \n",
      "\n",
      "MODEL CHOSEN: Random Forest\n",
      "\n",
      "[[340  25]\n",
      " [ 33 103]]\n",
      "Precision: 0.8046875\n",
      "Recall: 0.7573529411764706\n",
      "Accuracy: 0.8842315369261478\n",
      "Acuracy cv_scores mean:0.8856890547263682\n",
      "AUC:  0.9095588235294118\n",
      "cross-validated AUC:  0.9388696170030402 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPP_code</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>AFR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NA20876</th>\n",
       "      <td>SAS</td>\n",
       "      <td>0000101011011010111011100010000010100011101000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG01148</th>\n",
       "      <td>AMR</td>\n",
       "      <td>0110100011011010111010000110000010100010110000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG01366</th>\n",
       "      <td>AMR</td>\n",
       "      <td>0011100111011010111011000010000011100000110000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG01992</th>\n",
       "      <td>AMR</td>\n",
       "      <td>0110100011111010111011000010001011101001101010...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG01851</th>\n",
       "      <td>EAS</td>\n",
       "      <td>0001100000011000111011000010000011000101101000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA20901</th>\n",
       "      <td>SAS</td>\n",
       "      <td>0101110011011010110001100110000011110111111000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG02861</th>\n",
       "      <td>AFR</td>\n",
       "      <td>0011100001111110101000100110000011001011110000...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA18637</th>\n",
       "      <td>EAS</td>\n",
       "      <td>0100100000011000111011000010000001000101101000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG03809</th>\n",
       "      <td>SAS</td>\n",
       "      <td>0101110011001010111011100010000011110011111000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA18557</th>\n",
       "      <td>EAS</td>\n",
       "      <td>0000100010101000011011100010000001000011100010...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2504 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SPP_code                                           Sequence  AFR\n",
       "Patient                                                                 \n",
       "NA20876      SAS  0000101011011010111011100010000010100011101000...    0\n",
       "HG01148      AMR  0110100011011010111010000110000010100010110000...    0\n",
       "HG01366      AMR  0011100111011010111011000010000011100000110000...    0\n",
       "HG01992      AMR  0110100011111010111011000010001011101001101010...    0\n",
       "HG01851      EAS  0001100000011000111011000010000011000101101000...    0\n",
       "...          ...                                                ...  ...\n",
       "NA20901      SAS  0101110011011010110001100110000011110111111000...    0\n",
       "HG02861      AFR  0011100001111110101000100110000011001011110000...    1\n",
       "NA18637      EAS  0100100000011000111011000010000001000101101000...    0\n",
       "HG03809      SAS  0101110011001010111011100010000011110011111000...    0\n",
       "NA18557      EAS  0000100010101000011011100010000001000011100010...    0\n",
       "\n",
       "[2504 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop the ancestries we are not going to predict\n",
    "df_afr = main_df.drop(['EUR', 'ASIAN'], axis=1)\n",
    "df_afr.set_index(['Patient'],inplace=True)\n",
    "patients_afr_df=list(set(df_afr.index.get_level_values('Patient')))\n",
    "#len(patients_eur_df)\n",
    "\n",
    "modelData(df_afr, 'logreg')\n",
    "modelData(df_afr, 'knn')\n",
    "modelData(df_afr, 'gnb')\n",
    "modelData(df_afr, 'rfc')\n",
    "df_afr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 179],\n",
       "       [2306],\n",
       "       [1210],\n",
       "       ...,\n",
       "       [1418],\n",
       "       [2193],\n",
       "       [ 124]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_encoded = createLabelEncoder(df_afr)\n",
    "\n",
    "# Declare X and y variables\n",
    "x= seq_encoded\n",
    "x1D = seq_encoded\n",
    "x = x.reshape(-1, 1)\n",
    "y = df_afr[['AFR']]\n",
    "y = y.values\n",
    "#y = df_afr[df_afr.columns[2]].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, train_size=0.8,random_state=1)\n",
    "#X_train.sort_values(by='Patient')\n",
    "len(y_train)\n",
    "len(seq_encoded)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y = df_afr[df_afr.columns[2]].values\n",
    "#df_afr[[2]].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities [[8.79706314e-01 1.20293686e-01]\n",
      " [7.81652153e-01 2.18347847e-01]\n",
      " [9.99356611e-01 6.43389120e-04]\n",
      " ...\n",
      " [8.42203416e-01 1.57796584e-01]\n",
      " [9.89224798e-01 1.07752021e-02]\n",
      " [6.95784439e-01 3.04215561e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.73631841, 0.73631841, 0.73631841, 0.74      , 0.74      ,\n",
       "       0.74      , 0.74      , 0.74      , 0.735     , 0.735     ])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the class\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "gnb = GaussianNB()\n",
    "cv_scores = cross_val_score(gnb, X_train,np.ravel(y_train), cv=10,scoring='accuracy')\n",
    "\n",
    "# fit the model with data\n",
    "gnb.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred=gnb.predict(X_test)\n",
    "\n",
    "\n",
    "# print the first 10 predicted probabilities of class membership\n",
    "y_pred_prob=gnb.predict_proba(X_test)\n",
    "print(\"Predicted probabilities\",y_pred_prob)\n",
    "\n",
    "cv_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Majo Carbajal\\anaconda3\\envs\\amphora\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities [[0.80595955 0.19404045]\n",
      " [0.78245768 0.21754232]\n",
      " [0.88828109 0.11171891]\n",
      " ...\n",
      " [0.79652341 0.20347659]\n",
      " [0.85605724 0.14394276]\n",
      " [0.58468199 0.41531801]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "reg = LogisticRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "y_pred_prob=reg.predict_proba(X_test)\n",
    "print(\"Predicted probabilities\",y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ravel(y_train)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[365   0]\n",
      " [136   0]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "Accuracy: 0.7285429141716567\n",
      "Acuracy cv_scores mean:0.7378955223880597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Majo Carbajal\\anaconda3\\envs\\amphora\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Use the forest's predict method on the test data\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print('Acuracy cv_scores mean:{}'.format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8936140209508461\n",
      "cross-validated AUC:  0.8966706480183569\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "\n",
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "print(metrics.roc_auc_score(y_test, y_pred_prob[:, 1]))\n",
    "\n",
    "print(\"cross-validated AUC: \",cross_val_score(gnb, X_train,np.ravel(y_train), cv=10,scoring='roc_auc').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Asian ancestry Random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPP_code</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>ASIAN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NA20876</th>\n",
       "      <td>SAS</td>\n",
       "      <td>0000101011011010111011100010000010100011101000...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG01148</th>\n",
       "      <td>AMR</td>\n",
       "      <td>0110100011011010111010000110000010100010110000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG01366</th>\n",
       "      <td>AMR</td>\n",
       "      <td>0011100111011010111011000010000011100000110000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG01992</th>\n",
       "      <td>AMR</td>\n",
       "      <td>0110100011111010111011000010001011101001101010...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG01851</th>\n",
       "      <td>EAS</td>\n",
       "      <td>0001100000011000111011000010000011000101101000...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA20901</th>\n",
       "      <td>SAS</td>\n",
       "      <td>0101110011011010110001100110000011110111111000...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG02861</th>\n",
       "      <td>AFR</td>\n",
       "      <td>0011100001111110101000100110000011001011110000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA18637</th>\n",
       "      <td>EAS</td>\n",
       "      <td>0100100000011000111011000010000001000101101000...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG03809</th>\n",
       "      <td>SAS</td>\n",
       "      <td>0101110011001010111011100010000011110011111000...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA18557</th>\n",
       "      <td>EAS</td>\n",
       "      <td>0000100010101000011011100010000001000011100010...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2504 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SPP_code                                           Sequence  ASIAN\n",
       "Patient                                                                   \n",
       "NA20876      SAS  0000101011011010111011100010000010100011101000...      1\n",
       "HG01148      AMR  0110100011011010111010000110000010100010110000...      0\n",
       "HG01366      AMR  0011100111011010111011000010000011100000110000...      0\n",
       "HG01992      AMR  0110100011111010111011000010001011101001101010...      0\n",
       "HG01851      EAS  0001100000011000111011000010000011000101101000...      1\n",
       "...          ...                                                ...    ...\n",
       "NA20901      SAS  0101110011011010110001100110000011110111111000...      1\n",
       "HG02861      AFR  0011100001111110101000100110000011001011110000...      0\n",
       "NA18637      EAS  0100100000011000111011000010000001000101101000...      1\n",
       "HG03809      SAS  0101110011001010111011100010000011110011111000...      1\n",
       "NA18557      EAS  0000100010101000011011100010000001000011100010...      1\n",
       "\n",
       "[2504 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop the ancestries we are not going to predict\n",
    "df_asian = main_df.drop(['AFR', 'EUR'], axis=1)\n",
    "df_asian.set_index(['Patient'],inplace=True)\n",
    "patients_asian_df=list(set(df_asian.index.get_level_values('Patient')))\n",
    "#len(patients_eur_df)\n",
    "\n",
    "df_asian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL CHOSEN: Logistic Regression\n",
      "\n",
      "[[233  69]\n",
      " [ 73 126]]\n",
      "Precision: 0.6461538461538462\n",
      "Recall: 0.6331658291457286\n",
      "Accuracy: 0.716566866267465\n",
      "Acuracy cv_scores mean:0.7234129353233831\n",
      "AUC:  0.800434290658591\n",
      "cross-validated AUC:  0.8030138024374933 \n",
      "\n",
      "MODEL CHOSEN: KNN\n",
      "\n",
      "[[252  50]\n",
      " [ 72 127]]\n",
      "Precision: 0.7175141242937854\n",
      "Recall: 0.6381909547738693\n",
      "Accuracy: 0.7564870259481038\n",
      "Acuracy cv_scores mean:0.7518706467661692\n",
      "AUC:  0.8074395154580851\n",
      "cross-validated AUC:  0.8017391185662726 \n",
      "\n",
      "MODEL CHOSEN: Naive Bayes\n",
      "\n",
      "[[292  10]\n",
      " [179  20]]\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.10050251256281408\n",
      "Accuracy: 0.6227544910179641\n",
      "Acuracy cv_scores mean:0.6425124378109454\n",
      "AUC:  0.5472727877799594\n",
      "cross-validated AUC:  0.8043515714902186 \n",
      "\n",
      "MODEL CHOSEN: Random Forest\n",
      "\n",
      "[[233  69]\n",
      " [ 73 126]]\n",
      "Precision: 0.6461538461538462\n",
      "Recall: 0.6331658291457286\n",
      "Accuracy: 0.716566866267465\n",
      "Acuracy cv_scores mean:0.7234129353233831\n",
      "AUC:  0.795201171420014\n",
      "cross-validated AUC:  0.8023257662935455 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelData(df_asian, 'logreg')\n",
    "modelData(df_asian, 'knn')\n",
    "modelData(df_asian, 'gnb')\n",
    "modelData(df_asian, 'rfc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_encoded = createLabelEncoder(df_asian)\n",
    "\n",
    "# Declare X and y variables\n",
    "x= seq_encoded\n",
    "x1D = seq_encoded\n",
    "x = x.reshape(-1, 1)\n",
    "y = df_asian[['ASIAN']]\n",
    "y = y.values\n",
    "y = np.array(df_asian[['ASIAN']])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, train_size=0.8,random_state=1)\n",
    "#X_train.sort_values(by='Patient')\n",
    "type(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_asian.iloc[:,2])\n",
    "type(np.array(df_asian.iloc[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities [[0.75 0.25]\n",
      " [0.26 0.74]\n",
      " [0.33 0.67]\n",
      " ...\n",
      " [0.73 0.27]\n",
      " [0.18 0.82]\n",
      " [0.93 0.07]]\n"
     ]
    }
   ],
   "source": [
    "# import the class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "rfc = RandomForestClassifier()\n",
    "cv_scores = cross_val_score(rfc, X_train,np.ravel(y_train), cv=10,scoring='accuracy')\n",
    "\n",
    "# fit the model with data\n",
    "rfc.fit(X_train, y_train.ravel())\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred=rfc.predict(X_test)\n",
    "\n",
    "\n",
    "# print the first 10 predicted probabilities of class membership\n",
    "y_pred_prob=rfc.predict_proba(X_test)\n",
    "print(\"Predicted probabilities\",y_pred_prob)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[233  69]\n",
      " [ 73 126]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6461538461538462\n",
      "Recall: 0.6331658291457286\n",
      "Accuracy: 0.716566866267465\n",
      "Acuracy cv_scores mean:0.7234129353233831\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Use the forest's predict method on the test data\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print('Acuracy cv_scores mean:{}'.format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8070068887483776\n",
      "cross-validated AUC:  0.8007290081119015\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "\n",
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "print(metrics.roc_auc_score(y_test, y_pred_prob[:, 1]))\n",
    "\n",
    "print(\"cross-validated AUC: \",cross_val_score(rfc, X_train,np.ravel(y_train), cv=10,scoring='roc_auc').mean())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e12b99451188a96fe4605eb4c7ee05ee6f8d2932d13829995f682fb642b4e94"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('amphora')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
